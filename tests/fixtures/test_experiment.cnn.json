{
    "dataset_reader": {

      "type": "seq2seq",
      
      "source_tokenizer": {
        "type": "ngram",
        "max_ngram_degree": 2
      },
      
      "target_tokenizer": {
        "type": "word",
        "word_splitter": {"type": "just_spaces"}
      },
      
      "source_token_indexers": {
        "ngram_words": {
          "type": "words",
          "word_tokenizer": {
              "word_splitter": {"type": "just_spaces"},
              "end_tokens": ["@@PADDING@@", "@@PADDING@@", "@@PADDING@@", "@@PADDING@@"] 
          },
          "namespace": "shared_words_vocab"
        }
      },
      
      "target_token_indexers": {
           "tokens": { 
               "type": "single_id",
               "namespace": "shared_words_vocab"
           }
      }
    },

    "train_data_path": "tests/fixtures/seq2seq_copy.tsv",
    "validation_data_path": "tests/fixtures/seq2seq_copy.tsv",

    "model": {
      "type": "ngrams2seq",

      "source_embedder": {
        "ngram_words": {
            "type": "word_encoding",
            "embedding": {
                "embedding_dim": 50,
                "vocab_namespace": "shared_words_vocab"                
            },
            "encoder": {
              "type": "cnn",
              "embedding_dim": 50,
              "num_filters": 50,
              "ngram_filter_sizes": [5]
            },
        "dropout": 0
        }  
      },

      "encoder": {
        "type": "bypass_seq2seq",
        "input_dim": 50
      },

      "max_decoding_steps": 20,
      "target_namespace": "shared_words_vocab",
      "attention_function": {"type": "dot_product"},
      "scheduled_sampling_ratio": 1 // means not using teacher forcing

    },

    "iterator": {
      "type": "bucket",
      "padding_noise": 0.0,
      "batch_size" : 3
    },

    "trainer": {
      "num_epochs": 200,
      "patience": 10,
      "cuda_device": -1,
      "optimizer": {
        "type": "adam",
        "lr": 0.001
      }
    }

}
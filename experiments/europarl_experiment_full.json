{
    "dataset_reader": {

      "type": "seq2seq",
      
      "source_tokenizer": {
        "type": "ngram",
        "max_ngram_degree": 2
      },
      
      "target_tokenizer": {
        "type": "word",
        "word_splitter": {"type": "just_spaces"}
      },
      
      "source_token_indexers": {
        "ngram_words": {
          "type": "words",
          "word_tokenizer": {
              //"type": "word",
              "word_splitter": {"type": "just_spaces"}
          },
          "namespace": "shared_words_vocab"
        }
      },
      
      "target_token_indexers": {
           "tokens": { // seq2seq models uses this name to fetch tokens
           "type": "single_id",
           "namespace": "shared_words_vocab"
           }
      }
    },

    "train_data_path": "../../data/europarl/parallel_full.en",
    "validation_data_path": "../../data/europarl/parallel_dev.en",
    
    "model": {
      "type": "simple_ngrams2seq",

      "source_embedder": {
        "ngram_words": {
            "type": "character_encoding", // weak place; should be word_encoding
            "embedding": {
                "embedding_dim": 50,
                "vocab_namespace": "shared_words_vocab"                
            },
            "encoder": {
                "type": "boe",
                "embedding_dim": 50,
                "averaged": false
            },
        "dropout": 0
        }  
      },

      "encoder": {
        "type": "bypass_seq2seq",
        "input_dim": 50
      },

      "max_decoding_steps": 20,
      "target_namespace": "shared_words_vocab",
      "attention_function": {"type": "dot_product"},
      "scheduled_sampling_ratio": 1 // means not using teacher forcing

    },

    "iterator": {
      "type": "bucket",
      "padding_noise": 0.0,
      "batch_size" : 30 // should be changed
    },

    "trainer": {
      "num_epochs": 200,
      "patience": 10,
      "cuda_device": -1,
      "optimizer": {
        "type": "adam",
        "lr": 0.01
      }
    }

}